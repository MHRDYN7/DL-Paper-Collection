# DL-Paper-Collection
A collection of important deep learning papers that introduced features commonly used in latest model architectures

[RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864) (2021-2023)

[RMSNorm] [Root Mean Square Layer Normalization](https://arxiv.org/abs/1910.07467) (2019)

[Multi Query Attention] [Fast Transformer Decoding: One Write-Head is All You Need](https://arxiv.org/abs/1911.02150) (2019)

[Grouped Multi-Query Attention] [GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints](https://arxiv.org/abs/2305.13245v3) (2023)

# Potentially Helpful

[A Survey on Large Language Model Acceleration based on KV Cache Management](https://arxiv.org/abs/2412.19442) (2025)


